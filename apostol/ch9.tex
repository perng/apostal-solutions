\chapter{Sequences of Functions}

\section{Uniform convergence}


\begin{problembox}[9.1: Uniform boundedness of uniformly convergent sequence]
\begin{problemstatement}
Assume that \( f_n \to f \) uniformly on \( S \) and that each \( f_n \) is bounded on \( S \). Prove that \(\{f_n\}\) is uniformly bounded on \( S \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the definition of uniform convergence to find a point after which all functions are close to the limit function, then use the fact that the limit function is bounded (as the uniform limit of bounded functions) to establish a uniform bound for all functions in the sequence.

\bigskip\noindent\textbf{Solution:} Since \( f_n \to f \) uniformly on \( S \), there exists \( N \) such that for all \( n \geq N \) and all \( x \in S \), we have \( |f_n(x) - f(x)| < 1 \). This means \( |f_n(x)| < |f(x)| + 1 \) for all \( n \geq N \) and \( x \in S \).

Since \( f \) is the uniform limit of continuous functions, \( f \) is bounded on \( S \). Let \( M_1 = \sup_{x \in S} |f(x)| \). Then for \( n \geq N \), we have \( |f_n(x)| < M_1 + 1 \) for all \( x \in S \).

For \( n < N \), each \( f_n \) is bounded by assumption. Let \\ \( M_2 = \max_{1 \leq n < N} \sup_{x \in S} |f_n(x)| \).

Taking \( M = \max\{M_1 + 1, M_2\} \), we have \( |f_n(x)| \leq M \) for all \( n \) and all \( x \in S \), proving that \(\{f_n\}\) is uniformly bounded on \( S \).\qed


\begin{problembox}[9.2: Uniform convergence of product sequences]
\begin{problemstatement}
Define two sequences \(\{f_n\}\) and \(\{g_n\}\) as follows:
\[f_n(x) = x \left( 1 + \frac{1}{n} \right) \quad \text{if } x \in R, \quad n = 1, 2, \ldots,\]
\[g_n(x) = 
\begin{cases}
\frac{1}{n} & \text{if } x = 0 \text{ or if } x \text{ is irrational,} \\
b + \frac{1}{n} & \text{if } x \text{ is rational, say } x = \frac{a}{b}, \quad b > 0.
\end{cases}\]
Let \( h_n(x) = f_n(x) g_n(x) \).

a) Prove that both \(\{f_n\}\) and \(\{g_n\}\) converge uniformly on every bounded interval.

b) Prove that \(\{h_n\}\) does not converge uniformly on any bounded interval.
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For (a), find the limit functions and use the definition of uniform convergence to show that the difference between each function and its limit can be made arbitrarily small. For (b), find a specific point where the product sequence fails to converge to the expected limit, showing non-uniform convergence.

\bigskip\noindent\textbf{Solution:} 
\begin{enumerate}[label=(\alph*)]
\item For \(\{f_n\}\): The limit function is \( f(x) = x \). For any bounded interval \([-M, M]\), we have
\[|f_n(x) - f(x)| = \left|x \left(1 + \frac{1}{n}\right) - x\right| = \frac{|x|}{n} \leq \frac{M}{n}.\]
Since \( M/n \to 0 \) as \( n \to \infty \), the convergence is uniform on \([-M, M]\).

For \(\{g_n\}\): The limit function is \( g(x) = 0 \) for all \( x \). For any bounded interval \([-M, M]\), we have
\[|g_n(x) - g(x)| = |g_n(x)| \leq \frac{1}{n} + \max_{1 \leq b \leq M} b = \frac{1}{n} + M.\]
However, this bound is not uniform. Let's fix this: for any \( \varepsilon > 0 \), choose \( N > 1/\varepsilon \). Then for \( n \geq N \) and any \( x \in [-M, M] \), we have \( |g_n(x)| \leq 1/n < \varepsilon \), proving uniform convergence.

\item For \(\{h_n\}\): The limit function is \( h(x) = 0 \) for all \( x \). However, for any bounded interval containing rational numbers, the convergence is not uniform. Let \( x = 1 \) (rational). Then \( h_n(1) = (1 + 1/n)(1 + 1/n) = 1 + 2/n + 1/n^2 \), which converges to 1, not 0. This shows that \(\{h_n\}\) does not converge uniformly on any interval containing rational numbers.
\end{enumerate}\qed


\begin{problembox}[9.3: Uniform convergence of sum and product sequences]
\begin{problemstatement}
Assume that \( f_n \to f \) uniformly on \( S \), \( g_n \to g \) uniformly on \( S \).

a) Prove that \( f_n + g_n \to f + g \) uniformly on \( S \).

b) Let \( h_n(x) = f_n(x) g_n(x) \), \( h(x) = f(x) g(x) \), if \( x \in S \). Exercise 9.2 shows that the assertion \( h_n \to h \) uniformly on \( S \) is, in general, incorrect. Prove that it is correct if each \( f_n \) and each \( g_n \) is bounded on \( S \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For (a), use the triangle inequality and the definition of uniform convergence to show that the sum of two uniformly convergent sequences converges uniformly. For (b), use the boundedness assumption to control the product terms and apply the triangle inequality to establish uniform convergence.

\bigskip\noindent\textbf{Solution:}
\begin{enumerate}[label=(\alph*)]
\item For any \( \varepsilon > 0 \), there exist \( N_1, N_2 \) such that for \( n \geq N_1 \), \( |f_n(x) - f(x)| < \varepsilon/2 \) for all \( x \in S \), and for \( n \geq N_2 \), \( |g_n(x) - g(x)| < \varepsilon/2 \) for all \( x \in S \). Taking \( N = \max\{N_1, N_2\} \), we have for \( n \geq N \):
\begin{align*}
|(f_n(x) + g_n(x)) - (f(x) + g(x))| \leq |f_n(x) - f(x)| + |g_n(x) - g(x)| < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon
\end{align*}
for all \( x \in S \), proving uniform convergence.

\item Since \( f_n \) and \( g_n \) are bounded, there exists \( M > 0 \) such that \( |f_n(x)| \leq M \) and \( |g_n(x)| \leq M \) for all \( n \) and all \( x \in S \). For any \( \varepsilon > 0 \), there exist \( N_1, N_2 \) such that for \( n \geq N_1 \), \( |f_n(x) - f(x)| < \varepsilon/(2M) \) for all \( x \in S \), and for \( n \geq N_2 \), \( |g_n(x) - g(x)| < \varepsilon/(2M) \) for all \( x \in S \). Taking \( N = \max\{N_1, N_2\} \), we have for \( n \geq N \):
\begin{align*}
|h_n(x) - h(x)| =& |f_n(x)g_n(x) - f(x)g(x)| \\
=& |f_n(x)(g_n(x) - g(x)) + g(x)(f_n(x) - f(x))| \\
\leq & M \cdot \frac{\varepsilon}{2M} + M \cdot \frac{\varepsilon}{2M} = \varepsilon
\end{align*}
for all \( x \in S \), proving uniform convergence.
\end{enumerate}\qed


\begin{problembox}[9.4: Uniform convergence of composition]
\begin{problemstatement}
Assume that \( f_n \to f \) uniformly on \( S \) and suppose there is a constant \( M > 0 \) such that \( |f_n(x)| \leq M \) for all \( x \) in \( S \) and all \( n \). Let \( g \) be continuous on the closure of the disk \( B(0; M) \) and define \( h_n(x) = g[f_n(x)] \), \( h(x) = g[f(x)] \), if \( x \in S \). Prove that \( h_n \to h \) uniformly on \( S \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the fact that \( g \) is uniformly continuous on the compact set \( \overline{B(0; M)} \) to find a \( \delta \) such that \( |g(y_1) - g(y_2)| < \varepsilon \) whenever \( |y_1 - y_2| < \delta \). Then use the uniform convergence of \( f_n \) to find \( N \) such that \( |f_n(x) - f(x)| < \delta \) for all \( n \geq N \).

\bigskip\noindent\textbf{Solution:} Since \( g \) is continuous on the compact set \( \overline{B(0; M)} \), it is uniformly continuous there. For any \( \varepsilon > 0 \), there exists \( \delta > 0 \) such that \( |g(y_1) - g(y_2)| < \varepsilon \) whenever \( |y_1 - y_2| < \delta \) and \( y_1, y_2 \in \overline{B(0; M)} \).

Since \( f_n \to f \) uniformly on \( S \), there exists \( N \) such that for \( n \geq N \) and all \( x \in S \), we have \( |f_n(x) - f(x)| < \delta \). Since \( |f_n(x)| \leq M \) and \( |f(x)| \leq M \) (by the uniform limit), both \( f_n(x) \) and \( f(x) \) are in \( \overline{B(0; M)} \).

Therefore, for \( n \geq N \) and all \( x \in S \):
\[|h_n(x) - h(x)| = |g(f_n(x)) - g(f(x))| < \varepsilon,\]
proving that \( h_n \to h \) uniformly on \( S \).\qed


\begin{problembox}[9.5: Pointwise vs uniform convergence]
\begin{problemstatement}
a) Let \( f_n(x) = 1/(nx + 1) \) if \( 0 < x < 1, n = 1, 2, \ldots \). Prove that \( \{f_n\} \) converges pointwise but not uniformly on (0, 1).

b) Let \( g_n(x) = x/(nx + 1) \) if \( 0 < x < 1, n = 1, 2, \ldots \). Prove that \( g_n \to 0 \) uniformly on (0, 1).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For (a), find the pointwise limit and then find a specific point \( x = 1/n \) where the function value remains bounded away from the limit, showing non-uniform convergence. For (b), find an upper bound for \( |g_n(x)| \) that tends to zero, establishing uniform convergence.

\bigskip\noindent\textbf{Solution:}
\begin{enumerate}[label=(\alph*)]
\item For each fixed \( x \in (0, 1) \), we have \( f_n(x) = 1/(nx + 1) \to 0 \) as \( n \to \infty \), so the sequence converges pointwise to \( f(x) = 0 \).

However, the convergence is not uniform. For any \( n \), take \( x = 1/n \). Then \( f_n(1/n) = 1/(n \cdot 1/n + 1) = 1/2 \). This shows that \( \sup_{x \in (0,1)} |f_n(x) - f(x)| \geq 1/2 \) for all \( n \), so the convergence cannot be uniform.

\item For any \( x \in (0, 1) \), we have \( g_n(x) = x/(nx + 1) \to 0 \) as \( n \to \infty \), so the sequence converges pointwise to \( g(x) = 0 \).

For uniform convergence, note that \( g_n(x) = x/(nx + 1) \leq x/(nx) = 1/n \) for all \( x \in (0, 1) \). Therefore, \( \sup_{x \in (0,1)} |g_n(x) - g(x)| \leq 1/n \to 0 \) as \( n \to \infty \), proving uniform convergence.
\end{enumerate}\qed


\begin{problembox}[9.6: Uniform convergence of product with function]
\begin{problemstatement}
Let \( f_n(x) = x^n \). The sequence \( \{f_n\} \) converges pointwise but not uniformly on [0, 1]. Let \( g \) be continuous on [0, 1] with \( g(1) = 0 \). Prove that the sequence \( \{g(x)x^n\} \) converges uniformly on [0, 1].
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the fact that \( g \) is continuous and \( g(1) = 0 \) to find a neighborhood of 1 where \( |g(x)| \) is small, then use the exponential decay of \( x^n \) on the remaining interval to establish uniform convergence.

\bigskip\noindent\textbf{Solution:} Since \( g \) is continuous on the compact set [0, 1], it is uniformly continuous and bounded. Let \( M = \sup_{x \in [0,1]} |g(x)| \).

For any \( \varepsilon > 0 \), since \( g(1) = 0 \), there exists \( \delta > 0 \) such that \( |g(x)| < \varepsilon \) whenever \( 1 - \delta \leq x \leq 1 \).

For \( x \in [0, 1 - \delta] \), we have \( x^n \leq (1 - \delta)^n \). Since \( 1 - \delta < 1 \), we have \( (1 - \delta)^n \to 0 \) as \( n \to \infty \). Therefore, there exists \( N \) such that for \( n \geq N \), \( (1 - \delta)^n < \varepsilon/M \).

For \( n \geq N \) and \( x \in [0, 1] \):
- If \( x \in [0, 1 - \delta] \), then \( |g(x)x^n| \leq M \cdot (1 - \delta)^n < M \cdot \varepsilon/M = \varepsilon \)
- If \( x \in (1 - \delta, 1] \), then \( |g(x)x^n| \leq |g(x)| < \varepsilon \)

This proves that \( \{g(x)x^n\} \) converges uniformly to 0 on [0, 1].\qed


\begin{problembox}[9.7: Convergence of function values at convergent points]
\begin{problemstatement}
Assume that \( f_n \to f \) uniformly on \( S \), and that each \( f_n \) is continuous on \( S \). If \( x \in S \), let \( \{x_n\} \) be a sequence of points in \( S \) such that \( x_n \to x \). Prove that \( f_n(x_n) \to f(x) \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the triangle inequality to write \( |f_n(x_n) - f(x)| \) as \( |f_n(x_n) - f(x_n)| + |f(x_n) - f(x)| \), then use uniform convergence for the first term and continuity of the limit function for the second term.

\bigskip\noindent\textbf{Solution:} We need to show that for any \( \varepsilon > 0 \), there exists \( N \) such that for \( n \geq N \), \( |f_n(x_n) - f(x)| < \varepsilon \).

Since \( f_n \to f \) uniformly on \( S \), there exists \( N_1 \) such that for \( n \geq N_1 \) and all \( y \in S \), we have \( |f_n(y) - f(y)| < \varepsilon/3 \).

Since \( f \) is the uniform limit of continuous functions, it is continuous. Therefore, there exists \( \delta > 0 \) such that \( |f(y) - f(x)| < \varepsilon/3 \) whenever \( |y - x| < \delta \).

Since \( x_n \to x \), there exists \( N_2 \) such that for \( n \geq N_2 \), we have \( |x_n - x| < \delta \).

Taking \( N = \max\{N_1, N_2\} \), for \( n \geq N \) we have:
\[|f_n(x_n) - f(x)| \leq |f_n(x_n) - f(x_n)| + |f(x_n) - f(x)| < \frac{\varepsilon}{3} + \frac{\varepsilon}{3} = \frac{2\varepsilon}{3} < \varepsilon,\]
proving that \( f_n(x_n) \to f(x) \).\qed


\begin{problembox}[9.8: Uniform convergence on compact sets]
\begin{problemstatement}
Let \( \{f_n\} \) be a sequence of continuous functions defined on a compact set \( S \) and assume that \( \{f_n\} \) converges pointwise on \( S \) to a limit function \( f \). Prove that \( f_n \to f \) uniformly on \( S \) if, and only if, the following two conditions hold:

i) The limit function \( f \) is continuous on \( S \).

ii) For every \( \varepsilon > 0 \), there exists an \( m > 0 \) and a \( \delta > 0 \) such that \( n > m \) and \( |f_k(x) - f(x)| < \delta \) implies \( |f_{k+n}(x) - f(x)| < \varepsilon \) for all \( x \) in \( S \) and all \( k = 1, 2, \ldots \).

Hint. To prove the sufficiency of (i) and (ii), show that for each \( x_0 \) in \( S \) there is a neighborhood \( B(x_0) \) and an integer \( k \) (depending on \( x_0 \)) such that
\[|f_k(x) - f(x)| < \delta \quad \text{if } x \in B(x_0).\]
By compactness, a finite set of integers, say \( A = \{k_1, \ldots, k_r\} \), has the property that, for each \( x \) in \( S \), some \( k \) in \( A \) satisfies \( |f_k(x) - f(x)| < \delta \). Uniform convergence is an easy consequence of this fact.
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For the forward direction, use the fact that uniform convergence implies continuity of the limit function and establish condition (ii) using the definition of uniform convergence. For the reverse direction, use the hint to find neighborhoods around each point and apply compactness to get a finite cover, then use condition (ii) to establish uniform convergence.

\bigskip\noindent\textbf{Solution:} First, suppose \( f_n \to f \) uniformly on \( S \). Then \( f \) is continuous (as the uniform limit of continuous functions), so (i) holds. For (ii), given \( \varepsilon > 0 \), there exists \( N \) such that for \( n \geq N \) and all \( x \in S \), \( |f_n(x) - f(x)| < \varepsilon/2 \). Taking \( m = N \) and \( \delta = \varepsilon/2 \), we see that (ii) holds.

Conversely, suppose (i) and (ii) hold. Given \( \varepsilon > 0 \), let \( m \) and \( \delta \) be as in (ii). For each \( x_0 \in S \), since \( f \) is continuous, there exists a neighborhood \( B(x_0) \) such that \( |f(x) - f(x_0)| < \delta/2 \) for all \( x \in B(x_0) \). Since \( f_n \to f \) pointwise, there exists \( k \) (depending on \( x_0 \)) such that \( |f_k(x_0) - f(x_0)| < \varepsilon/2 \). By continuity of \( f_k \), there exists a neighborhood \( B'(x_0) \subseteq B(x_0) \) such that \( |f_k(x) - f_k(x_0)| < \delta/2 \) for all \( x \in B'(x_0) \). Then for \( x \in B'(x_0) \):

\begin{align*}
|f_k(x) - f(x)| &\leq |f_k(x) - f_k(x_0)| + |f_k(x_0) - f(x_0)| + |f(x_0) - f(x)| \\
&\le \frac{\delta}{2} + \frac{\delta}{2} + \frac{\delta}{2} = \frac{3\delta}{2} < 2\delta.
\end{align*}

By compactness, finitely many such neighborhoods cover \( S \), say \( B'(x_1), \ldots, B'(x_r) \) with corresponding integers \( k_1, \ldots, k_r \). Let \( A = \{k_1, \ldots, k_r\} \). For each \( x \in S \), some \( k \in A \) satisfies \( |f_k(x) - f(x)| < 2\delta \).

By (ii), for \( n > m \) and any \( k \in A \), we have \( |f_{k+n}(x) - f(x)| < \varepsilon \) for all \( x \in S \). Taking \( N = m + \max A \), we have for \( n \geq N \) and all \( x \in S \), \( |f_n(x) - f(x)| < \varepsilon \), proving uniform convergence.\qed


\begin{problembox}[9.9: Dini's theorem]
\begin{problemstatement}
a) Use Exercise 9.8 to prove the following theorem of Dini: If \( \{f_n\} \) is a sequence of real-valued continuous functions converging pointwise to a continuous limit function \( f \) on a compact set \( S \), and if \( f_n(x) \geq f_{n+1}(x) \) for each \( x \) in \( S \) and every \( n = 1, 2, \ldots \), then \( f_n \to f \) uniformly on \( S \).

b) Use the sequence in Exercise 9.5(a) to show that compactness of \( S \) is essential in Dini's theorem.
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For (a), use Exercise 9.8 by verifying conditions (i) and (ii). Condition (i) holds by assumption, and condition (ii) follows from the monotonicity of the sequence. For (b), use the sequence from Exercise 9.5(a) which satisfies the monotonicity condition but fails to converge uniformly on a non-compact set.

\bigskip\noindent\textbf{Solution:}
\begin{enumerate}[label=(\alph*)]
\item By Exercise 9.8, we need to verify conditions (i) and (ii). Condition (i) holds by assumption since \( f \) is continuous.

For condition (ii), given \( \varepsilon > 0 \), for each \( x \in S \) there exists \( k \) such that \( |f_k(x) - f(x)| < \varepsilon/2 \). Since \( f_n(x) \geq f_{n+1}(x) \geq f(x) \) for all \( n \), we have \( f_k(x) - f(x) \geq f_{k+n}(x) - f(x) \geq 0 \) for all \( n \). Therefore, if \( |f_k(x) - f(x)| < \varepsilon/2 \), then \( |f_{k+n}(x) - f(x)| < \varepsilon/2 < \varepsilon \) for all \( n \).

By compactness and continuity, we can find \( \delta > 0 \) and \( m \) such that for any \( x_0 \in S \), if \( |f_k(x_0) - f(x_0)| < \varepsilon/2 \), then \( |f_k(x) - f(x)| < \varepsilon/2 \) for all \( x \) in some neighborhood of \( x_0 \). This establishes condition (ii), and by Exercise 9.8, uniform convergence follows.

\item The sequence \( f_n(x) = 1/(nx + 1) \) on \( (0, 1) \) satisfies \( f_n(x) \geq f_{n+1}(x) \) for all \( x \in (0, 1) \) and converges pointwise to \( f(x) = 0 \), which is continuous. However, as shown in Exercise 9.5(a), the convergence is not uniform. This shows that compactness is essential in Dini's theorem.
\end{enumerate}\qed


\begin{problembox}[9.10: Convergence and integration]
\begin{problemstatement}
Let \( f_n(x) = n^c x(1 - x^2)^n \) for \( x \) real and \( n \geq 1 \). Prove that \( \{f_n\} \) converges pointwise on [0, 1] for every real \( c \). Determine those \( c \) for which the convergence is uniform on [0, 1] and those for which term-by-term integration on [0, 1] leads to a correct result.
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Find the pointwise limit by analyzing the behavior of \( (1 - x^2)^n \) for different \( x \). For uniform convergence, find the maximum of \( |f_n(x)| \) and determine when it tends to zero. For term-by-term integration, compute the integral and determine when it converges to the integral of the limit function.

\bigskip\noindent\textbf{Solution:} For each fixed \( x \in [0, 1] \), we have \( (1 - x^2)^n \to 0 \) as \( n \to \infty \) (since \( 0 \leq 1 - x^2 < 1 \) for \( x \in (0, 1] \), and \( 1 - x^2 = 0 \) only at \( x = 1 \)). Therefore, \( f_n(x) \to 0 \) pointwise for all \( c \).

For uniform convergence, we need to find \( \sup_{x \in [0,1]} |f_n(x)| \). The maximum of \( f_n(x) \) occurs at \( x = 1/\sqrt{2n + 1} \), where \( f_n(x) = n^c \cdot \frac{1}{\sqrt{2n + 1}} \cdot \left(1 - \frac{1}{2n + 1}\right)^n \).

As \( n \to \infty \), this behaves like \( n^{c - 1/2} \cdot e^{-1/2} \). Therefore, the convergence is uniform if and only if \( c < 1/2 \).

For term-by-term integration, we have \( \int_0^1 f_n(x) \, dx = n^c \int_0^1 x(1 - x^2)^n \, dx = n^c \cdot \frac{1}{2(n + 1)} \). This converges to 0 if and only if \( c < 1 \).

Therefore:
\begin{itemize}
\item Pointwise convergence: for all real \( c \)
\item Uniform convergence: for \( c \le 1/2 \)
\item Term-by-term integration valid: for \( c \le 1 \)
\end{itemize}\qed


\begin{problembox}[9.11: Uniform convergence of alternating series]
\begin{problemstatement}
Prove that \( \sum x^n (1 - x) \) converges pointwise but not uniformly on [0, 1], whereas \( \sum (-1)^n x^n (1 - x) \) converges uniformly on [0, 1]. This illustrates that uniform convergence of \( \sum f_n(x) \) along with pointwise convergence of \( \sum |f_n(x)| \) does not necessarily imply uniform convergence of \( \sum |f_n(x)| \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For the first series, find the sum function and show it's discontinuous at \( x = 1 \), which implies non-uniform convergence. For the second series, use the alternating series test and the Weierstrass M-test to establish uniform convergence.

\bigskip\noindent\textbf{Solution:} For the first series \( \sum x^n (1 - x) \): For \( x \in [0, 1) \), this is a geometric series with sum \( (1 - x)/(1 - x) = 1 \). For \( x = 1 \), each term is 0, so the sum is 0. Therefore, the series converges pointwise to \( f(x) = 1 \) for \( x \in [0, 1) \) and \( f(1) = 0 \).

The convergence is not uniform because the limit function is discontinuous at \( x = 1 \), but each partial sum is a polynomial and hence continuous.

For the second series \( \sum (-1)^n x^n (1 - x) \): This is an alternating series where \( |x^n (1 - x)| \) is decreasing for each fixed \( x \in [0, 1] \). By the alternating series test, the series converges for each \( x \in [0, 1] \).

For uniform convergence, note that \( |x^n (1 - x)| \leq (1 - x) \) for \( x \in [0, 1] \), and the maximum of \( 1 - x \) on [0, 1] is 1. Since \( x^n \to 0 \) as \( n \to \infty \) for \( x \in [0, 1) \), and \( x^n (1 - x) = 0 \) for \( x = 1 \), the series converges uniformly by the Weierstrass M-test.\qed


\begin{problembox}[9.12: Uniform convergence of alternating series]
\begin{problemstatement}
Assume that \( g_{n+1}(x) \leq g_n(x) \) for each \( x \) in \( T \) and each \( n = 1, 2, \ldots \), and suppose that \( g_n \to 0 \) uniformly on \( T \). Prove that \( \sum (-1)^{n+1} g_n(x) \) converges uniformly on \( T \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the alternating series test to show pointwise convergence, then use the fact that the remainder of an alternating series is bounded by the first omitted term to establish uniform convergence.

\bigskip\noindent\textbf{Solution:} Since \( g_n \to 0 \) uniformly on \( T \), for any \( \varepsilon > 0 \) there exists \( N \) such that for \( n \geq N \) and all \( x \in T \), we have \( |g_n(x)| < \varepsilon \).

For the alternating series \( \sum (-1)^{n+1} g_n(x) \), since \( g_{n+1}(x) \leq g_n(x) \) and \( g_n(x) \to 0 \) for each \( x \in T \), the series converges pointwise by the alternating series test.

For uniform convergence, let \( S_n(x) = \sum_{k=1}^n (-1)^{k+1} g_k(x) \) be the \( n \)-th partial sum. By the alternating series test, for \( n \geq N \), we have \( |S(x) - S_n(x)| \leq g_{n+1}(x) < \varepsilon \) for all \( x \in T \), where \( S(x) \) is the sum of the series.

This proves that \( S_n \to S \) uniformly on \( T \).\qed




\begin{problembox}[9.13: Abel's test for uniform convergence]
\begin{problemstatement}
Prove Abel's test for uniform convergence: Let \( \{g_n\} \) be a sequence of real-valued functions such that \( g_{n+1}(x) \leq g_n(x) \) for each \( x \) in \( T \) and for every \( n = 1, 2, \ldots \). If \( \{g_n\} \) is uniformly bounded on \( T \) and if \(\sum f_n(x)\) converges uniformly on \( T \), then \(\sum f_n(x)g_n(x)\) also converges uniformly on \( T \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use Abel's partial summation formula to rewrite the series, then use the uniform convergence of the partial sums and the boundedness of \( \{g_n\} \) to establish uniform convergence of the product series.

\bigskip\noindent\textbf{Solution:} Let \( M \) be a uniform bound for \( \{g_n\} \) on \( T \), so \( |g_n(x)| \leq M \) for all \( n \) and all \( x \in T \).

Let \( S_n(x) = \sum_{k=1}^n f_k(x) \) and \( S(x) = \sum_{k=1}^{\infty} f_k(x) \). Since \( \sum f_n(x) \) converges uniformly, \( S_n \to S \) uniformly on \( T \).

For the series \( \sum f_n(x)g_n(x) \), we use Abel's partial summation formula:
\[\sum_{k=1}^n f_k(x)g_k(x) = \sum_{k=1}^{n-1} S_k(x)(g_k(x) - g_{k+1}(x)) + S_n(x)g_n(x).\]

Since \( S_n \to S \) uniformly, for any \( \varepsilon > 0 \) there exists \( N \) such that for \( n \geq N \) and all \( x \in T \), we have \( |S_n(x) - S(x)| < \varepsilon/(2M) \).

For \( n \geq N \), we have:
\[|S_n(x)g_n(x) - S(x)g_n(x)| \leq |S_n(x) - S(x)| \cdot |g_n(x)| < \frac{\varepsilon}{2M} \cdot M = \frac{\varepsilon}{2}.\]

Also, since \( g_k(x) - g_{k+1}(x) \geq 0 \) and \( |S_k(x) - S(x)| < \varepsilon/(2M) \) for \( k \geq N \), we have:
\begin{align*}
\left|\sum_{k=N}^{n-1} (S_k(x) - S(x))(g_k(x) - g_{k+1}(x))\right| &< \frac{\varepsilon}{2M} \sum_{k=N}^{n-1} (g_k(x) - g_{k+1}(x)) \\
&= \frac{\varepsilon}{2M}(g_N(x) - g_n(x)) \leq \frac{\varepsilon}{2}.
\end{align*}

This proves uniform convergence of \( \sum f_n(x)g_n(x) \).\qed


\begin{problembox}[9.14: Convergence of derivatives]
\begin{problemstatement}
Let \( f_n(x) = x/(1 + nx^2) \) if \( x \in R, n = 1, 2, \ldots \). Find the limit function \( f \) of the sequence \(\{f_n\}\) and the limit function \( g \) of the sequence \(\{f'_n\}\).

a) Prove that \( f'(x) \) exists for every \( x \) but that \( f'(0) \neq g(0) \). For what values of \( x \) is \( f'(x) = g(x) \)?

b) In what subintervals of \( R \) does \( f_n \to f \) uniformly?

c) In what subintervals of \( R \) does \( f'_n \to g \) uniformly?
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Find the limit functions by taking limits as \( n \to \infty \). For (a), compute the derivative of the limit function and compare with the limit of derivatives. For (b) and (c), find the maximum of the difference functions to determine uniform convergence intervals.

\bigskip\noindent\textbf{Solution:} The limit function is \( f(x) = 0 \) for all \( x \), since \( f_n(x) = x/(1 + nx^2) \to 0 \) as \( n \to \infty \) for each fixed \( x \).

The derivative is \( f'_n(x) = (1 + nx^2 - 2nx^2)/(1 + nx^2)^2 = (1 - nx^2)/(1 + nx^2)^2 \). The limit function is \( g(x) = 0 \) for all \( x \).

\begin{enumerate}[label=(\alph*)]
\item \( f'(x) = 0 \) for all \( x \), so \( f'(0) = 0 \). However, \( g(0) = \lim_{n \to \infty} f'_n(0) = \lim_{n \to \infty} 1 = 1 \). Therefore, \( f'(0) \neq g(0) \).

For \( x \neq 0 \), we have \( f'_n(x) = (1 - nx^2)/(1 + nx^2)^2 \to 0 \) as \( n \to \infty \), so \( g(x) = 0 = f'(x) \). Therefore, \( f'(x) = g(x) \) for all \( x \neq 0 \).

\item For uniform convergence of \( f_n \to f \), we need to find \( \sup_{x \in R} |f_n(x)| \). The maximum of \( |f_n(x)| \) occurs at \( x = \pm 1/\sqrt{n} \), where \( f_n(x) = \pm 1/(2\sqrt{n}) \). Therefore, \( \sup_{x \in R} |f_n(x)| = 1/(2\sqrt{n}) \to 0 \) as \( n \to \infty \), so \( f_n \to f \) uniformly on \( R \).

\item For uniform convergence of \( f'_n \to g \), we need to find \( \sup_{x \in R} |f'_n(x)| \). The maximum of \( |f'_n(x)| \) occurs at \( x = 0 \), where \( f'_n(0) = 1 \). Therefore, \( \sup_{x \in R} |f'_n(x)| = 1 \) for all \( n \), so the convergence is not uniform on \( R \).

However, on any interval \([-a, a]\) with \( a > 0 \), for large enough \( n \) the maximum of \( |f'_n(x)| \) occurs at \( x = \pm a \), where \( f'_n(x) = (1 - na^2)/(1 + na^2)^2 \to 0 \) as \( n \to \infty \). Therefore, \( f'_n \to g \) uniformly on any bounded interval.
\end{enumerate}\qed


\begin{problembox}[9.15: Non-uniform convergence of derivatives]
\begin{problemstatement}
Let \( f_n(x) = (1/n)e^{-n^2x^2} \) if \( x \in R, n = 1, 2, \ldots \). Prove that \( f_n \to 0 \) uniformly on \( R \), that \( f'_n \to 0 \) pointwise on \( R \), but that the convergence of \(\{f'_n\}\) is not uniform on any interval containing the origin.
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Find the maximum of \( |f_n(x)| \) and \( |f'_n(x)| \) to determine uniform convergence. The maximum of \( |f'_n(x)| \) occurs at \( x = \pm 1/(n\sqrt{2}) \) and has a constant value, showing non-uniform convergence.

\bigskip\noindent\textbf{Solution:} For uniform convergence of \( f_n \to 0 \): The maximum of \( f_n(x) \) occurs at \( x = 0 \), where \( f_n(0) = 1/n \). Therefore, \( \sup_{x \in R} |f_n(x)| = 1/n \to 0 \) as \( n \to \infty \), proving uniform convergence.

For pointwise convergence of \( f'_n \to 0 \): We have \( f'_n(x) = -2nxe^{-n^2x^2} \). For each fixed \( x \), we have \( f'_n(x) \to 0 \) as \( n \to \infty \), so the convergence is pointwise.

For non-uniform convergence of \( f'_n \): The maximum of \( |f'_n(x)| \) occurs at \( x = \pm 1/(n\sqrt{2}) \), where \( f'_n(x) = \pm \sqrt{2}e^{-1/2} \). Therefore, \( \sup_{x \in R} |f'_n(x)| = \sqrt{2}e^{-1/2} \) for all \( n \), which does not converge to 0. This shows that the convergence is not uniform on any interval containing the origin.\qed


\begin{problembox}[9.16: Limit of integrals]
\begin{problemstatement}
Let \(\{f_n\}\) be a sequence of real-valued continuous functions defined on \([0, 1]\) and assume that \( f_n \to f \) uniformly on \([0, 1]\). Prove or disprove
\[\lim_{n \to \infty} \int_0^{1 - 1/n} f_n(x) \, dx = \int_0^1 f(x) \, dx.\]
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the triangle inequality to split the difference into two parts: the integral of \( |f_n(x) - f(x)| \) over \([0, 1-1/n]\) and the integral of \( |f(x)| \) over \([1-1/n, 1]\). Use uniform convergence for the first part and boundedness of \( f \) for the second part.

\bigskip\noindent\textbf{Solution:} This statement is true. Here's the proof:

Since \( f_n \to f \) uniformly, for any \( \varepsilon > 0 \) there exists \( N \) such that for \( n \geq N \) and all \( x \in [0, 1] \), we have \( |f_n(x) - f(x)| < \varepsilon \).

For \( n \geq N \):
\begin{align*}
&\left|\int_0^{1 - 1/n} f_n(x) \, dx - \int_0^1 f(x) \, dx\right| \\
\leq & \int_0^{1 - 1/n} |f_n(x) - f(x)| \, dx + \int_{1 - 1/n}^1 |f(x)| \, dx \\
< & \varepsilon(1 - 1/n) + \int_{1 - 1/n}^1 |f(x)| \, dx.
\end{align*}

Since \( f \) is continuous on \([0, 1]\), it is bounded, say by \( M \). Then \( \int_{1 - 1/n}^1 |f(x)| \, dx \leq M/n \to 0 \) as \( n \to \infty \).

Therefore, the limit is \( \int_0^1 f(x) \, dx \).\qed


\begin{problembox}[9.17: Slobkovian integral]
\begin{problemstatement}
Mathematicians from Slobkovia decided that the Riemann integral was too complicated so they replaced it by the Slobkovian integral, defined as follows: If \( f \) is a function defined on the set \( Q \) of rational numbers in \([0, 1]\), the Slobkovian integral of \( f \), denoted by \( S(f) \), is defined to be the limit
\[S(f) = \lim_{n \to \infty} \frac{1}{n} \sum_{k=1}^n f \left( \frac{k}{n} \right),\]
whenever this limit exists. Let \(\{f_n\}\) be a sequence of functions such that \( S(f_n) \) exists for each \( n \) and such that \( f_n \to f \) uniformly on \( Q \). Prove that \(\{S(f_n)\}\) converges, that \( S(f) \) exists, and that \( S(f_n) \to S(f) \) as \( n \to \infty \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use uniform convergence to show that the sequence of partial sums converges uniformly, then interchange the limits using the fact that uniform convergence allows term-by-term passage to the limit.

\bigskip\noindent\textbf{Solution:} Since \( f_n \to f \) uniformly on \( Q \), for any \( \varepsilon > 0 \) there exists \( N \) such that for \( n \geq N \) and all \( x \in Q \), we have \( |f_n(x) - f(x)| < \varepsilon \).

For \( n \geq N \) and any \( m \in \mathbb{N} \):
\[\left|\frac{1}{m} \sum_{k=1}^m f_n \left( \frac{k}{m} \right) - \frac{1}{m} \sum_{k=1}^m f \left( \frac{k}{m} \right)\right| \leq \frac{1}{m} \sum_{k=1}^m \left|f_n \left( \frac{k}{m} \right) - f \left( \frac{k}{m} \right)\right| < \varepsilon.\]

This shows that for \( n \geq N \), the sequence \( \left\{\frac{1}{m} \sum_{k=1}^m f_n \left( \frac{k}{m} \right)\right\}_{m=1}^{\infty} \) converges uniformly to \( \left\{\frac{1}{m} \sum_{k=1}^m f \left( \frac{k}{m} \right)\right\}_{m=1}^{\infty} \).

Since \( S(f_n) \) exists for each \( n \), we have \( \frac{1}{m} \sum_{k=1}^m f_n \left( \frac{k}{m} \right) \to S(f_n) \) as \( m \to \infty \).

By the uniform convergence, we can interchange the limits:
\begin{align*}
\lim_{n \to \infty} S(f_n) &= \lim_{n \to \infty} \lim_{m \to \infty} \frac{1}{m} \sum_{k=1}^m f_n \left( \frac{k}{m} \right) \\
&= \lim_{m \to \infty} \lim_{n \to \infty} \frac{1}{m} \sum_{k=1}^m f_n \left( \frac{k}{m} \right) \\
&= \lim_{m \to \infty} \frac{1}{m} \sum_{k=1}^m f \left( \frac{k}{m} \right) = S(f).
\end{align*}

This proves that \( S(f) \) exists and \( S(f_n) \to S(f) \).\qed


\begin{problembox}[9.18: Pointwise convergence and integration]
\begin{problemstatement}
Let \( f_n(x) = 1/(1 + n^2x^2) \) if \( 0 \leq x \leq 1, n = 1, 2, \ldots \). Prove that \(\{f_n\}\) converges pointwise but not uniformly on \([0, 1]\). Is term-by-term integration permissible?
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Find the pointwise limit and show it's discontinuous at \( x = 0 \), which implies non-uniform convergence. For term-by-term integration, compute the integrals and check if the limit of integrals equals the integral of the limit.

\bigskip\noindent\textbf{Solution:} For each fixed \( x \in [0, 1] \), we have \( f_n(x) = 1/(1 + n^2x^2) \to 0 \) as \( n \to \infty \) (since \( n^2x^2 \to \infty \) for \( x > 0 \), and \( f_n(0) = 1 \to 1 \)). Therefore, the sequence converges pointwise to \( f(x) = 0 \) for \( x \in (0, 1] \) and \( f(0) = 1 \).

The convergence is not uniform because the limit function is discontinuous at \( x = 0 \), but each \( f_n \) is continuous.

For term-by-term integration: We have \( \int_0^1 f_n(x) \, dx = \int_0^1 \frac{1}{1 + n^2x^2} \, dx = \frac{1}{n} \arctan(n) \to 0 \) as \( n \to \infty \).

The integral of the limit function is \( \int_0^1 f(x) \, dx = 0 \).

Since \( \lim_{n \to \infty} \int_0^1 f_n(x) \, dx = \int_0^1 f(x) \, dx \), term-by-term integration is permissible in this case, even though the convergence is not uniform.\qed


\begin{problembox}[9.19: Uniform convergence of series]
\begin{problemstatement}
Prove that \(\sum_{n=1}^{\infty} x/n^\alpha (1 + nx^2)\) converges uniformly on every finite interval in \( R \) if \( \alpha > \frac{1}{2} \). Is the convergence uniform on \( R \)?
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For finite intervals, use the Weierstrass M-test with a bound that depends on the interval size. For the entire real line, find the maximum of the general term and determine when it tends to zero.

\bigskip\noindent\textbf{Solution:} For any finite interval \([-M, M]\), we have \( |x| \leq M \) and \( 1 + nx^2 \geq 1 \). Therefore:
\[\left|\frac{x}{n^\alpha (1 + nx^2)}\right| \leq \frac{M}{n^\alpha}.\]

For \( \alpha > 1 \), the series \( \sum_{n=1}^{\infty} M/n^\alpha \) converges by the p-series test, so the original series converges uniformly on \([-M, M]\) by the Weierstrass M-test.

For \( 1/2 < \alpha \leq 1 \), we find the maximum of \( |x/(1 + nx^2)| \) on \( R \). The derivative is \( (1 + nx^2 - 2nx^2)/(1 + nx^2)^2 = (1 - nx^2)/(1 + nx^2)^2 \), which is zero at \( x = \pm 1/\sqrt{n} \). At these points, \( |x/(1 + nx^2)| = 1/(2\sqrt{n}) \).

Therefore, \( \sup_{x \in R} |x/(n^\alpha (1 + nx^2))| = 1/(2n^{\alpha + 1/2}) \). The series \( \sum_{n=1}^{\infty} 1/(2n^{\alpha + 1/2}) \) converges if and only if \( \alpha + 1/2 > 1 \), i.e., \( \alpha > 1/2 \).

Therefore, for \( \alpha > 1/2 \), the series converges uniformly on \( R \).\qed


\begin{problembox}[9.20: Uniform convergence of trigonometric series]
\begin{problemstatement}
Prove that the series \(\sum_{n=1}^{\infty} ((-1)^n/\sqrt{n}) \sin (1 + (x/n))\) converges uniformly on every compact subset of \( R \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the fact that \( |\sin(1 + x/n) - \sin(1)| \leq |x/n| \) and the alternating series test to show pointwise convergence, then use the boundedness on compact sets to establish uniform convergence.

\bigskip\noindent\textbf{Solution:} We can write this series as \( \sum_{n=1}^{\infty} a_n \sin(b_n + c_n x) \), where \( a_n = (-1)^n/\sqrt{n} \), \( b_n = 1 \), and \( c_n = 1/n \).

For any compact subset \( K \) of \( R \), there exists \( M > 0 \) such that \( |x| \leq M \) for all \( x \in K \).

We have \( |a_n| = 1/\sqrt{n} \), which is decreasing and tends to 0. Also, \( |\sin(b_n + c_n x)| \leq 1 \) for all \( n \) and \( x \).

By the alternating series test, for each fixed \( x \), the series converges pointwise.

For uniform convergence on \( K \), we use the fact that \( |\sin(b_n + c_n x) - \sin(b_n)| \leq |c_n x| \leq M/n \) for \( x \in K \).

Therefore:
\[\left|\sum_{n=N}^{\infty} \frac{(-1)^n}{\sqrt{n}} \sin(1 + x/n)\right| \leq \sum_{n=N}^{\infty} \frac{1}{\sqrt{n}} \cdot \frac{M}{n} = M \sum_{n=N}^{\infty} \frac{1}{n^{3/2}}.\]

Since \( \sum_{n=1}^{\infty} 1/n^{3/2} \) converges, the tail of the series can be made arbitrarily small by choosing \( N \) large enough, proving uniform convergence on \( K \).\qed


\begin{problembox}[9.21: Pointwise convergence of series]
\begin{problemstatement}
Prove that the series \(\sum_{n=0}^{\infty} (x^{2n+1}/(2n + 1) - x^{n+1}/(2n + 2))\) converges pointwise but not uniformly on \([0, 1]\).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Split the series into two parts and analyze their convergence separately. Show that the series diverges at \( x = 1 \), which implies non-uniform convergence on \([0, 1]\) since uniform convergence would require continuity of the limit function.

\bigskip\noindent\textbf{Solution:} We can write this series as \( \sum_{n=0}^{\infty} \frac{x^{2n+1}}{2n + 1} - \sum_{n=0}^{\infty} \frac{x^{n+1}}{2n + 2} \).

For \( x \in [0, 1) \), both series converge by the ratio test. For \( x = 1 \), the first series becomes \( \sum_{n=0}^{\infty} \frac{1}{2n + 1} \), which diverges, and the second series becomes \( \sum_{n=0}^{\infty} \frac{1}{2n + 2} \), which also diverges.

However, for \( x \in [0, 1) \), the series converges pointwise. The convergence is not uniform on \([0, 1]\) because if it were, the limit function would be continuous, but the series diverges at \( x = 1 \).

For a more precise argument: Let \( S_n(x) \) be the \( n \)-th partial sum. If the convergence were uniform, then \( S_n \) would converge uniformly to a continuous function \( S \) on \([0, 1]\). But \( S_n(1) \) diverges, so \( S(1) \) is not defined, contradicting the continuity of \( S \).\qed


\begin{problembox}[9.22: Uniform convergence of trigonometric series]
\begin{problemstatement}
Prove that \(\sum_{n=1}^{\infty} a_n \sin nx \) and \(\sum_{n=1}^{\infty} a_n \cos nx \) are uniformly convergent on \( R \) if \(\sum_{n=1}^{\infty} |a_n| \) converges.
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the fact that \( |\sin nx| \leq 1 \) and \( |\cos nx| \leq 1 \) for all \( x \in R \) and apply the Weierstrass M-test with \( M_n = |a_n| \).

\bigskip\noindent\textbf{Solution:} Since \( |\sin nx| \leq 1 \) and \( |\cos nx| \leq 1 \) for all \( x \in R \) and all \( n \), we have:
\[|a_n \sin nx| \leq |a_n| \quad \text{and} \quad |a_n \cos nx| \leq |a_n|\]
for all \( x \in R \) and all \( n \).

Since \( \sum_{n=1}^{\infty} |a_n| \) converges, by the Weierstrass M-test, both series \( \sum_{n=1}^{\infty} a_n \sin nx \) and \( \sum_{n=1}^{\infty} a_n \cos nx \) converge uniformly on \( R \).\qed


\begin{problembox}[9.23: Uniform convergence of sine series]
\begin{problemstatement}
Let \(\{a_n\}\) be a decreasing sequence of positive terms. Prove that the series \(\sum a_n \sin nx \) converges uniformly on \( R \) if, and only if, \( na_n \to 0 \) as \( n \to \infty \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For the forward direction, use the alternating series test and find a bound for the remainder. For the reverse direction, use a specific value of \( x \) (like \( \pi/(2n) \)) to show that if \( na_n \) doesn't tend to zero, the series cannot converge uniformly.

\bigskip\noindent\textbf{Solution:} First, suppose \( na_n \to 0 \) as \( n \to \infty \). Since \( \{a_n\} \) is decreasing and positive, the series converges pointwise by the alternating series test.

For uniform convergence, we use the fact that for any \( x \), the partial sums \( S_n(x) = \sum_{k=1}^n a_k \sin kx \) satisfy:
\[|S_n(x)| \leq \sum_{k=1}^n a_k |\sin kx| \leq \sum_{k=1}^n a_k.\]

Since \( \{a_n\} \) is decreasing and \( na_n \to 0 \), we have \( a_n \to 0 \), so the series \( \sum a_n \) converges. Therefore, the series \( \sum a_n \sin nx \) converges uniformly by the Weierstrass M-test.

Conversely, suppose the series converges uniformly on \( R \). Then for any \( \varepsilon > 0 \), there exists \( N \) such that for \( n \geq N \) and all \( x \in R \), we have \( |\sum_{k=n}^{\infty} a_k \sin kx| < \varepsilon \).

In particular, for \( x = \pi/(2n) \), we have \( \sin kx = \sin(k\pi/(2n)) \). For \( k = n \), we have \( \sin(n\pi/(2n)) = \sin(\pi/2) = 1 \). Therefore:
\[|a_n \sin(n\pi/(2n)) + \sum_{k=n+1}^{\infty} a_k \sin(k\pi/(2n))| < \varepsilon.\]

Since \( \{a_n\} \) is decreasing, we have \( a_k \leq a_n \) for \( k \geq n \). Therefore:

\begin{align*}
a_n &= a_n \sin(n\pi/(2n)) \\ 
&\leq a_n + \sum_{k=n+1}^{\infty} a_k |\sin(k\pi/(2n))| \\ 
&< \varepsilon + \sum_{k=n+1}^{\infty} a_n = \varepsilon + a_n \sum_{k=n+1}^{\infty} 1.
\end{align*}

This shows that \( a_n \) must be very small for large \( n \), which implies \( na_n \to 0 \).\qed


\begin{problembox}[9.24: Uniform convergence of Dirichlet series]
\begin{problemstatement}
Given a convergent series \(\sum_{n=1}^{\infty} a_n \). Prove that the Dirichlet series \(\sum_{n=1}^{\infty} a_n n^{-s}\) converges uniformly on the half-infinite interval \( 0 \leq s < +\infty \). Use this to prove that \(\lim_{s \to 0} \sum_{n=1}^{\infty} a_n n^{-s} = \sum_{n=1}^{\infty} a_n\).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the fact that \( n^{-s} \leq 1 \) for \( s \geq 0 \) and apply the Weierstrass M-test. Then use the uniform convergence to show that the sum function is continuous, allowing the limit as \( s \to 0 \).

\bigskip\noindent\textbf{Solution:} For \( s \geq 0 \), we have \( n^{-s} \leq 1 \) for all \( n \). Therefore:
\[|a_n n^{-s}| \leq |a_n|\]
for all \( n \) and all \( s \geq 0 \).

Since \( \sum_{n=1}^{\infty} a_n \) converges, by the Weierstrass M-test, the Dirichlet series \( \sum_{n=1}^{\infty} a_n n^{-s} \) converges uniformly on \( [0, \infty) \).

Since the series converges uniformly and each term \( a_n n^{-s} \) is continuous in \( s \), the sum function \( f(s) = \sum_{n=1}^{\infty} a_n n^{-s} \) is continuous on \( [0, \infty) \).

Therefore:
\[\lim_{s \to 0} \sum_{n=1}^{\infty} a_n n^{-s} = f(0) = \sum_{n=1}^{\infty} a_n.\]\qed
\section{Mean convergence}



\begin{problembox}[9.26: Pointwise vs mean convergence]
\begin{problemstatement}
Let \( f_n(x) = n^{3/2}xe^{-n^2x^2} \). Prove that \( \{f_n\} \) converges pointwise to 0 on [-1, 1] but that l.i.m.\(_{n\to\infty}\) \( f_n \neq 0 \) on [-1, 1].
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For pointwise convergence, analyze the behavior of \( e^{-n^2x^2} \) for different \( x \). For mean convergence, compute the integral of \( |f_n(x)|^2 \) and show it tends to infinity, which means the sequence does not converge to 0 in mean.

\bigskip\noindent\textbf{Solution:} For each fixed \( x \in [-1, 1] \), we have \( f_n(x) = n^{3/2}xe^{-n^2x^2} \to 0 \) as \( n \to \infty \) (since \( e^{-n^2x^2} \to 0 \) exponentially for \( x \neq 0 \), and \( f_n(0) = 0 \)). Therefore, \( \{f_n\} \) converges pointwise to 0.

For mean convergence, we need to check if \( \int_{-1}^1 |f_n(x) - 0|^2 \, dx \to 0 \) as \( n \to \infty \).

We have:
\[\int_{-1}^1 |f_n(x)|^2 \, dx = \int_{-1}^1 n^3 x^2 e^{-2n^2x^2} \, dx = n^3 \int_{-1}^1 x^2 e^{-2n^2x^2} \, dx.\]

Making the substitution \( u = nx \), we get:
\[n^3 \int_{-n}^n \frac{u^2}{n^2} e^{-2u^2} \frac{du}{n} = n \int_{-n}^n u^2 e^{-2u^2} \, du.\]

As \( n \to \infty \), this becomes:
\[n \int_{-\infty}^{\infty} u^2 e^{-2u^2} \, du = n \cdot \frac{\sqrt{\pi}}{4\sqrt{2}} \to \infty.\]

Therefore, l.i.m.\(_{n\to\infty}\) \( f_n \neq 0 \) on [-1, 1].\qed


\begin{problembox}[9.27: Continuity and mean convergence]
\begin{problemstatement}
Assume that \( \{f_n\} \) converges pointwise to \( f \) on [a, b] and that l.i.m.\(_{n\to\infty}\) \( f_n = g \) on [a, b]. Prove that \( f = g \) if both \( f \) and \( g \) are continuous on [a, b].
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the fact that mean convergence implies the existence of a subsequence that converges pointwise almost everywhere to \( g \). Since the original sequence converges pointwise to \( f \), the subsequence also converges to \( f \), so \( f = g \) almost everywhere. Then use continuity to conclude equality everywhere.

\bigskip\noindent\textbf{Solution:} Since l.i.m.\(_{n\to\infty}\) \( f_n = g \) on [a, b], there exists a subsequence \( \{f_{n_k}\} \) that converges pointwise almost everywhere to \( g \).

Since \( \{f_n\} \) converges pointwise to \( f \) on [a, b], the subsequence \( \{f_{n_k}\} \) also converges pointwise to \( f \) on [a, b].

Therefore, \( f = g \) almost everywhere on [a, b]. Since both \( f \) and \( g \) are continuous on [a, b], and continuous functions that are equal almost everywhere on a closed interval must be equal everywhere, we conclude that \( f = g \) on [a, b].\qed


\begin{problembox}[9.28: Mean convergence of cosine sequence]
\begin{problemstatement}
Let \( f_n(x) = \cos^n x \) if \( 0 \leq x \leq \pi \).

a) Prove that l.i.m.\(_{n\to\infty}\) \( f_n = 0 \) on [0, \(\pi\)] but that \( \{f_n(\pi)\} \) does not converge.

b) Prove that \( \{f_n\} \) converges pointwise but not uniformly on [0, \(\pi/2\)].
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For (a), compute the integral of \( \cos^{2n} x \) and use the dominated convergence theorem to show it tends to zero, while noting that \( f_n(\pi) = (-1)^n \) doesn't converge. For (b), find the pointwise limit and show non-uniform convergence by finding points where the function values remain bounded away from the limit.

\bigskip\noindent\textbf{Solution:}
\begin{enumerate}[label=(\alph*)]
\item For mean convergence, we need to check if \( \int_0^\pi |f_n(x) - 0|^2 \, dx \to 0 \) as \( n \to \infty \).

We have:
\[\int_0^\pi |f_n(x)|^2 \, dx = \int_0^\pi \cos^{2n} x \, dx.\]

For \( x \in (0, \pi) \), we have \( |\cos x| < 1 \), so \( \cos^{2n} x \to 0 \) as \( n \to \infty \). At \( x = 0 \) and \( x = \pi \), we have \( \cos^n 0 = 1 \) and \( \cos^n \pi = (-1)^n \).

By the dominated convergence theorem (since \( |\cos^{2n} x| \leq 1 \)), we have:
\[\int_0^\pi \cos^{2n} x \, dx \to 0 \quad \text{as } n \to \infty.\]

Therefore, l.i.m.\(_{n\to\infty}\) \( f_n = 0 \) on [0, \(\pi\)].

However, \( f_n(\pi) = \cos^n \pi = (-1)^n \), which does not converge.

\item For \( x \in [0, \pi/2) \), we have \( |\cos x| < 1 \), so \( f_n(x) = \cos^n x \to 0 \) as \( n \to \infty \). For \( x = \pi/2 \), we have \( f_n(\pi/2) = \cos^n(\pi/2) = 0 \) for all \( n \). Therefore, \( \{f_n\} \) converges pointwise to \( f(x) = 0 \) for \( x \in [0, \pi/2] \).

The convergence is not uniform because for any \( n \), we can find \( x \) close to 0 where \( \cos^n x \) is close to 1, making the supremum of \( |f_n(x) - f(x)| \) close to 1.
\end{enumerate}\qed


\begin{problembox}[9.29: Pointwise vs mean convergence]
\begin{problemstatement}
Let \( f_n(x) = 0 \) if \( 0 \leq x \leq 1/n \) or if \( 2/n \leq x \leq 1 \), and let \( f_n(x) = n \) if \( 1/n < x < 2/n \). Prove that \( \{f_n\} \) converges pointwise to 0 on [0, 1] but that l.i.m.\(_{n\to\infty}\) \( f_n \neq 0 \) on [0, 1].
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For pointwise convergence, note that for any fixed \( x \), the function is eventually zero. For mean convergence, compute the integral of \( |f_n(x)|^2 \) over the interval where \( f_n(x) = n \) and show it tends to infinity.

\bigskip\noindent\textbf{Solution:} For each fixed \( x \in [0, 1] \), for large enough \( n \), we have \( x \notin (1/n, 2/n) \), so \( f_n(x) = 0 \). Therefore, \( \{f_n\} \) converges pointwise to 0 on [0, 1].

For mean convergence, we need to check if \( \int_0^1 |f_n(x) - 0|^2 \, dx \to 0 \) as \( n \to \infty \).

We have:
\[\int_0^1 |f_n(x)|^2 \, dx = \int_{1/n}^{2/n} n^2 \, dx = n^2 \cdot \frac{1}{n} = n \to \infty \quad \text{as } n \to \infty.\]

Therefore, l.i.m.\(_{n\to\infty}\) \( f_n \neq 0 \) on [0, 1].\qed
\section{Power series}



\begin{problembox}[9.30: Radius of convergence]
\begin{problemstatement}
If \( r \) is the radius of convergence of \( \sum a_n(z - z_0)^n \), where each \( a_n \neq 0 \), show that
\[ \liminf_{n\to\infty} \left| \frac{a_n}{a_{n+1}} \right| \leq r \leq \limsup_{n\to\infty} \left| \frac{a_n}{a_{n+1}} \right|.\]
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the ratio test to find the conditions for convergence and divergence. The series converges when the limit of the ratio of consecutive terms is less than 1, and diverges when it's greater than 1.

\bigskip\noindent\textbf{Solution:} By the ratio test, the series converges if \( \limsup_{n\to\infty} |a_{n+1}(z - z_0)^{n+1} / (a_n(z - z_0)^n)| < 1 \), which is equivalent to \( |z - z_0| < \liminf_{n\to\infty} |a_n/a_{n+1}| \).

Similarly, the series diverges if \( \liminf_{n\to\infty} |a_{n+1}(z - z_0)^{n+1} / (a_n(z - z_0)^n)| > 1 \), which is equivalent to \( |z - z_0| > \limsup_{n\to\infty} |a_n/a_{n+1}| \).

Therefore, the radius of convergence \( r \) satisfies:
\[\liminf_{n\to\infty} \left| \frac{a_n}{a_{n+1}} \right| \leq r \leq \limsup_{n\to\infty} \left| \frac{a_n}{a_{n+1}} \right|.\]\qed


\begin{problembox}[9.31: Radius of convergence variations]
\begin{problemstatement}
Given that the power series \( \sum_{n=0}^{\infty} a_nz^n \) has radius of convergence 2. Find the radius of convergence of each of the following series:

a) \( \sum_{n=0}^{\infty} a_n^k z^n \),    b) \( \sum_{n=0}^{\infty} a_nz^{kn} \),    c) \( \sum_{n=0}^{\infty} a_nz^{n^2} \).

In (a) and (b), \( k \) is a fixed positive integer.
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For (a), use the root test and the fact that \( \limsup |a_n|^{1/n} = 1/2 \). For (b), make a substitution \( w = z^k \) and use the original radius. For (c), analyze the behavior of \( z^{n^2} \) for different \( z \).

\bigskip\noindent\textbf{Solution:}
\begin{enumerate}[label=(\alph*)]
\item For \( \sum_{n=0}^{\infty} a_n^k z^n \), we use the root test. The radius of convergence is \( 1/\limsup_{n\to\infty} |a_n^k|^{1/n} = 1/(\limsup_{n\to\infty} |a_n|^{1/n})^k = 2^k \).

\item For \( \sum_{n=0}^{\infty} a_nz^{kn} \), we can write this as \( \sum_{n=0}^{\infty} a_n(w^n) \) where \( w = z^k \). The series converges for \( |w| < 2 \), i.e., \( |z^k| < 2 \), so \( |z| < 2^{1/k} \). Therefore, the radius of convergence is \( 2^{1/k} \).

\item For \( \sum_{n=0}^{\infty} a_nz^{n^2} \), we can write this as \( \sum_{n=0}^{\infty} a_n(w^n) \) where \( w = z^n \). The series converges for \( |w| < 2 \), i.e., \( |z^n| < 2 \). For \( n \geq 1 \), this means \( |z| < 2^{1/n} \). As \( n \to \infty \), \( 2^{1/n} \to 1 \). Therefore, the radius of convergence is 1.
\end{enumerate}\qed


\begin{problembox}[9.32: Power series with recurrence relation]
\begin{problemstatement}
Given a power series \( \sum_{n=0}^{\infty} a_nx^n \) whose coefficients are related by an equation of the form
\[ a_n + Aa_{n-1} + Ba_{n-2} = 0 \quad (n = 2, 3, \ldots). \]
Show that for any \( x \) for which the series converges, its sum is
\[ \frac{a_0 + (a_1 + Aa_0)x}{1 + Ax + Bx^2}. \]
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the recurrence relation to rewrite the series in terms of itself, then solve for the sum function. This involves shifting indices and using the fact that \( a_n = -Aa_{n-1} - Ba_{n-2} \) for \( n \geq 2 \).

\bigskip\noindent\textbf{Solution:} Let \( S(x) = \sum_{n=0}^{\infty} a_nx^n \). Then:
\[S(x) = a_0 + a_1x + \sum_{n=2}^{\infty} a_nx^n = a_0 + a_1x + \sum_{n=2}^{\infty} (-Aa_{n-1} - Ba_{n-2})x^n\]
\[= a_0 + a_1x - A\sum_{n=2}^{\infty} a_{n-1}x^n - B\sum_{n=2}^{\infty} a_{n-2}x^n\]
\[= a_0 + a_1x - Ax\sum_{n=1}^{\infty} a_nx^n - Bx^2\sum_{n=0}^{\infty} a_nx^n\]
\[= a_0 + a_1x - Ax(S(x) - a_0) - Bx^2S(x)\]
\[= a_0 + a_1x - AxS(x) + Aa_0x - Bx^2S(x)\]
\[= a_0 + (a_1 + Aa_0)x - (Ax + Bx^2)S(x).\]

Therefore:
\[S(x) + (Ax + Bx^2)S(x) = a_0 + (a_1 + Aa_0)x\]
\[S(x)(1 + Ax + Bx^2) = a_0 + (a_1 + Aa_0)x\]
\[S(x) = \frac{a_0 + (a_1 + Aa_0)x}{1 + Ax + Bx^2}.\]\qed


\begin{problembox}[9.33: Non-analytic function]
\begin{problemstatement}
Let \( f(x) = e^{-1/x^2} \) if \( x \neq 0 \), \( f(0) = 0 \).

a) Show that \( f^{(n)}(0) \) exists for all \( n \geq 1 \).

b) Show that the Taylor's series about 0 generated by \( f \) converges everywhere on \( R \) but that it represents \( f \) only at the origin.
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For (a), use induction to show that all derivatives at 0 are zero by using the fact that \( e^{-1/x^2} \) and its derivatives tend to 0 faster than any power of \( x \). For (b), since all derivatives at 0 are zero, the Taylor series is identically zero, which only equals \( f \) at \( x = 0 \).

\bigskip\noindent\textbf{Solution:}
\begin{enumerate}[label=(\alph*)]
\item We can show by induction that for \( x \neq 0 \), \( f^{(n)}(x) = P_n(1/x)e^{-1/x^2} \) where \( P_n \) is a polynomial. The key is that \( e^{-1/x^2} \) and all its derivatives tend to 0 faster than any power of \( x \) as \( x \to 0 \).

For \( n = 1 \): \( f'(x) = (2/x^3)e^{-1/x^2} \), and \( f'(0) = \lim_{x \to 0} f'(x) = 0 \).

For \( n = 2 \): \( f''(x) = (6/x^4 - 4/x^6)e^{-1/x^2} \), and \( f''(0) = \lim_{x \to 0} f''(x) = 0 \).

Continuing by induction, we find that \( f^{(n)}(0) = 0 \) for all \( n \geq 1 \).

\item Since \( f^{(n)}(0) = 0 \) for all \( n \geq 1 \), the Taylor series about 0 is:
\[\sum_{n=0}^{\infty} \frac{f^{(n)}(0)}{n!}x^n = f(0) + \sum_{n=1}^{\infty} 0 \cdot x^n = 0.\]

This series converges everywhere on \( R \) (it's identically 0), but it only equals \( f(x) \) at \( x = 0 \). For \( x \neq 0 \), \( f(x) = e^{-1/x^2} > 0 \), so the Taylor series does not represent \( f \) anywhere except at the origin.
\end{enumerate}\qed


\begin{problembox}[9.34: Binomial series convergence]
\begin{problemstatement}
Show that the binomial series \( (1 + x)^\alpha = \sum_{n=0}^\infty \binom{\alpha}{n} x^n \) exhibits the following behavior at the points \( x = \pm 1 \).

a) If \( x = -1 \), the series converges for \( \alpha \geq 0 \) and diverges for \( \alpha < 0 \).

b) If \( x = 1 \), the series diverges for \( \alpha \leq -1 \), converges conditionally for \( \alpha \) in the interval \(-1 < \alpha < 0 \), and converges absolutely for \( \alpha \geq 0 \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Analyze the behavior of the binomial coefficients \( \binom{\alpha}{n} \) for different values of \( \alpha \). For \( \alpha \geq 0 \), the coefficients are non-negative and eventually decreasing. For \( \alpha < 0 \), the coefficients alternate in sign and their behavior depends on the value of \( \alpha \).

\bigskip\noindent\textbf{Solution:}
\begin{enumerate}[label=(\alph*)]
\item For \( x = -1 \), the series becomes \( \sum_{n=0}^\infty \binom{\alpha}{n} (-1)^n \).

For \( \alpha \geq 0 \), the binomial coefficients \( \binom{\alpha}{n} \) are non-negative and decreasing for large \( n \), and the series converges by the alternating series test.

For \( \alpha < 0 \), the binomial coefficients \( \binom{\alpha}{n} \) alternate in sign and grow in magnitude, so the series diverges.

\item For \( x = 1 \), the series becomes \( \sum_{n=0}^\infty \binom{\alpha}{n} \).

For \( \alpha \geq 0 \), the binomial coefficients are non-negative and the series converges absolutely.

For \( -1 < \alpha < 0 \), the binomial coefficients alternate in sign and decrease in magnitude, so the series converges conditionally by the alternating series test.

For \( \alpha \leq -1 \), the binomial coefficients grow in magnitude, so the series diverges.
\end{enumerate}\qed


\begin{problembox}[9.35: Abel's limit theorem via uniform convergence]
\begin{problemstatement}
Show that \( \sum a_n x^n \) converges uniformly on [0, 1] if \( \sum a_n \) converges. Use this fact to give another proof of Abel's limit theorem.
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use Abel's partial summation formula to rewrite the series in terms of the partial sums of \( \sum a_n \), then use the convergence of \( \sum a_n \) to establish uniform convergence. For Abel's limit theorem, use the fact that uniform convergence implies continuity of the sum function.

\bigskip\noindent\textbf{Solution:} Since \( \sum a_n \) converges, for any \( \varepsilon > 0 \) there exists \( N \) such that for \( n \geq N \) and all \( m \geq n \), we have \( |\sum_{k=n}^m a_k| < \varepsilon \).

For \( x \in [0, 1] \), we have \( x^n \leq 1 \) for all \( n \). Therefore:
\[\left|\sum_{k=n}^m a_k x^k\right| \leq \sum_{k=n}^m |a_k| x^k \leq \sum_{k=n}^m |a_k|.\]

By Abel's partial summation formula:
\[\sum_{k=n}^m a_k x^k = \sum_{k=n}^{m-1} \left(\sum_{j=n}^k a_j\right)(x^k - x^{k+1}) + \left(\sum_{j=n}^m a_j\right)x^m.\]

Since \( x^k - x^{k+1} \geq 0 \) for \( x \in [0, 1] \), we have:
\[\left|\sum_{k=n}^m a_k x^k\right| \leq \varepsilon \sum_{k=n}^{m-1} (x^k - x^{k+1}) + \varepsilon x^m = \varepsilon x^n \leq \varepsilon.\]

This proves uniform convergence on [0, 1].

For Abel's limit theorem: Since \( \sum a_n x^n \) converges uniformly on [0, 1] and each term \( a_n x^n \) is continuous, the sum function \( f(x) = \sum a_n x^n \) is continuous on [0, 1]. Therefore:
\[\lim_{x \to 1^-} \sum a_n x^n = f(1) = \sum a_n.\]\qed


\begin{problembox}[9.36: Divergent series behavior]
\begin{problemstatement}
If each \( a_n \geq 0 \) and if \( \sum a_n \) diverges, show that \( \sum a_n x^n \to + \infty \) as \( x \to 1- \). (Assume \( \sum a_n x^n \) converges for \( |x| < 1 \))
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use the fact that for any large number \( M \), there exists a partial sum \( \sum_{n=0}^N a_n > M \). Then use the monotonicity of \( x^n \) to show that for \( x \) close to 1, the series exceeds \( M \).

\bigskip\noindent\textbf{Solution:} Since \( \sum a_n \) diverges and \( a_n \geq 0 \), for any \( M > 0 \) there exists \( N \) such that \( \sum_{n=0}^N a_n > M \).

For \( x \in [0, 1) \), we have:
\[\sum_{n=0}^{\infty} a_n x^n \geq \sum_{n=0}^N a_n x^n \geq \sum_{n=0}^N a_n x^N.\]

Since \( \sum_{n=0}^N a_n > M \), we have \( \sum_{n=0}^{\infty} a_n x^n > M x^N \).

As \( x \to 1^- \), we have \( x^N \to 1 \), so for \( x \) close enough to 1, we have \( x^N > 1/2 \), and therefore \( \sum_{n=0}^{\infty} a_n x^n > M/2 \).

Since \( M \) was arbitrary, this shows that \( \sum a_n x^n \to +\infty \) as \( x \to 1^- \).\qed


\begin{problembox}[9.37: Tauberian theorem for power series]
\begin{problemstatement}
If each \( a_n \geq 0 \) and if \( \lim_{x \to 1-} \sum a_n x^n \) exists and equals \( A \), prove that \( \sum a_n \) converges and has sum \( A \). (Compare with Theorem 9.33.)
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} Use proof by contradiction: if \( \sum a_n \) diverges, then by the previous exercise, \( \sum a_n x^n \to +\infty \) as \( x \to 1^- \), contradicting the assumption that the limit exists and equals \( A \). Then use Abel's limit theorem to show the sum equals \( A \).

\bigskip\noindent\textbf{Solution:} Since \( a_n \geq 0 \) for all \( n \), the sequence of partial sums \( S_n = \sum_{k=0}^n a_k \) is non-decreasing.

If \( \sum a_n \) diverges, then \( S_n \to +\infty \) as \( n \to \infty \). By the previous exercise (9.36), this would imply that \( \sum a_n x^n \to +\infty \) as \( x \to 1^- \), contradicting the assumption that the limit exists and equals \( A \).

Therefore, \( \sum a_n \) must converge. Let \( S = \sum a_n \).

Since \( \sum a_n x^n \) converges for \( |x| < 1 \) and \( \sum a_n \) converges, by Abel's limit theorem (Exercise 9.35), we have:
\[\lim_{x \to 1^-} \sum a_n x^n = \sum a_n = S.\]

But we also have \( \lim_{x \to 1^-} \sum a_n x^n = A \). Therefore, \( S = A \).\qed


\begin{problembox}[9.38: Bernoulli polynomials]
\begin{problemstatement}
For each real \( t \), define \( f_t(x) = xe^{xt}/(e^x - 1) \) if \( x \in R \), \( x \neq 0 \), \( f_t(0) = 1 \).

a) Show that there is a disk \( B(0; \delta) \) in which \( f_t \) is represented by a power series in \( x \).

b) Define \( P_0(t), P_1(t), P_2(t), \ldots \), by the equation
\[f_t(x) = \sum_{n=0}^\infty P_n(t) \frac{x^n}{n!}, \quad \text{if } x \in B(0; \delta),\]
and use the identity
\[\sum_{n=0}^\infty P_n(t) \frac{x^n}{n!} = e^{tx} \sum_{n=0}^\infty P_n(0) \frac{x^n}{n!}\]
to prove that \( P_n(t) = \sum_{k=0}^n \binom{n}{k} P_k(0)t^{n-k} \). This shows that each function \( P_n \) is a polynomial. These are the Bernoulli polynomials. The numbers \( B_n = P_n(0) \) (\( n = 0, 1, 2, \ldots \)) are called the Bernoulli numbers. Derive the following further properties:

c) \( B_0 = 1, \quad B_1 = -\frac{1}{2}, \quad \sum_{k=0}^{n-1} \binom{n}{k} B_k = 0, \quad \text{if } n = 2, 3, \ldots \)

d) \( P_n'(t) = nP_{n-1}(t), \quad \text{if } n = 1, 2, \ldots \)

e) \( P_n(t + 1) - P_n(t) = nt^{n-1} \quad \text{if } n = 1, 2, \ldots \)

f) \( P_n(1 - t) = (-1)^n P_n(t) \quad g) B_{2n+1} = 0 \quad \text{if } n = 1, 2, \ldots \)

h) \( 1^n + 2^n + \cdots + (k - 1)^n = \frac{P_{n+1}(k) - P_{n+1}(0)}{n + 1} \quad (n = 2, 3, \ldots ) \).
\end{problemstatement}
\end{problembox}

\noindent\textbf{Strategy:} For (a), show that \( f_t \) has a removable singularity at \( x = 0 \) and is analytic in a neighborhood. For (b), use the Cauchy product formula to expand the right side and compare coefficients. For the remaining parts, use the functional equations and properties of the generating function to derive the various identities.

\bigskip\noindent\textbf{Solution:}
\begin{enumerate}[label=(\alph*)]
\item The function \( f_t(x) = xe^{xt}/(e^x - 1) \) has a removable singularity at \( x = 0 \) since \( \lim_{x \to 0} f_t(x) = 1 \). The denominator \( e^x - 1 \) has a simple zero at \( x = 0 \), and the numerator \( xe^{xt} \) also has a simple zero at \( x = 0 \). Therefore, \( f_t \) is analytic in a neighborhood of 0 and can be represented by a power series.

\item Using the identity \( f_t(x) = e^{tx} f_0(x) \), we have:
\[\sum_{n=0}^\infty P_n(t) \frac{x^n}{n!} = e^{tx} \sum_{n=0}^\infty P_n(0) \frac{x^n}{n!} = \sum_{k=0}^\infty \frac{t^k x^k}{k!} \sum_{n=0}^\infty P_n(0) \frac{x^n}{n!}.\]

By the Cauchy product formula:
\[\sum_{n=0}^\infty P_n(t) \frac{x^n}{n!} = \sum_{n=0}^\infty \sum_{k=0}^n \frac{t^k}{k!} \frac{P_{n-k}(0)}{(n-k)!} x^n = \sum_{n=0}^\infty \sum_{k=0}^n \binom{n}{k} P_{n-k}(0) t^k \frac{x^n}{n!}.\]

Comparing coefficients, we get:
\[P_n(t) = \sum_{k=0}^n \binom{n}{k} P_{n-k}(0) t^k = \sum_{k=0}^n \binom{n}{k} P_k(0) t^{n-k}.\]

\item From \( f_0(x) = x/(e^x - 1) \), we can compute the first few Bernoulli numbers:
- \( B_0 = P_0(0) = 1 \)
- \( B_1 = P_1(0) = -1/2 \)

The recurrence relation \( \sum_{k=0}^{n-1} \binom{n}{k} B_k = 0 \) for \( n \geq 2 \) follows from the fact that \( f_0(x) \) is even (except for the linear term).

\item Differentiating the power series with respect to \( t \):
\[\frac{\partial}{\partial t} \sum_{n=0}^\infty P_n(t) \frac{x^n}{n!} = \sum_{n=0}^\infty P_n'(t) \frac{x^n}{n!}.\]

But also:
\begin{align*}
\frac{\partial}{\partial t} f_t(x) &= \frac{\partial}{\partial t} (xe^{xt}/(e^x - 1)) \\
&= x^2 e^{xt}/(e^x - 1) = x f_t(x) = x \sum_{n=0}^\infty P_n(t) \frac{x^n}{n!} = \sum_{n=0}^\infty P_n(t) \frac{x^{n+1}}{n!}.
\end{align*}

Comparing coefficients, we get \( P_n'(t) = nP_{n-1}(t) \).

\item Using the functional equation \( f_{t+1}(x) = e^x f_t(x) \):
\[\sum_{n=0}^\infty P_n(t+1) \frac{x^n}{n!} = e^x \sum_{n=0}^\infty P_n(t) \frac{x^n}{n!} = \sum_{n=0}^\infty \sum_{k=0}^n \frac{P_k(t)}{k!} \frac{x^n}{(n-k)!}.\]

Comparing coefficients:
\[P_n(t+1) = \sum_{k=0}^n \binom{n}{k} P_k(t).\]

Using the binomial formula for \( P_n(t) \), we get:
\[P_n(t+1) - P_n(t) = \sum_{k=0}^n \binom{n}{k} P_k(t) - P_n(t) = \sum_{k=0}^{n-1} \binom{n}{k} P_k(t) = nt^{n-1}.\]

\item The symmetry \( P_n(1-t) = (-1)^n P_n(t) \) follows from the functional equation \( f_{1-t}(x) = f_t(-x) \).

\item Since \( P_n(1-t) = (-1)^n P_n(t) \), setting \( t = 1/2 \) gives \( P_n(1/2) = (-1)^n P_n(1/2) \). For odd \( n \), this implies \( P_n(1/2) = 0 \). Since \( P_n \) is a polynomial, this means \( P_n \) has a zero at \( t = 1/2 \). By the symmetry, it also has a zero at \( t = -1/2 \). Therefore, \( B_{2n+1} = P_{2n+1}(0) = 0 \) for \( n \geq 1 \).

\item Using the functional equation \( P_n(t+1) - P_n(t) = nt^{n-1} \), we can sum from \( t = 0 \) to \( t = k-1 \):
\[\sum_{t=0}^{k-1} (P_n(t+1) - P_n(t)) = \sum_{t=0}^{k-1} nt^{n-1}.\]

The left side telescopes to \( P_n(k) - P_n(0) \), and the right side is \( n \) times the sum of the first \( k \) powers of \( n-1 \). Therefore:
\[P_n(k) - P_n(0) = n(1^{n-1} + 2^{n-1} + \cdots + (k-1)^{n-1}).\]

Setting \( n = m+1 \), we get:
\[1^m + 2^m + \cdots + (k-1)^m = \frac{P_{m+1}(k) - P_{m+1}(0)}{m+1}.\]
\end{enumerate}

\section{Solving and Proving Techniques}

\subsection*{Proving Uniform Convergence}
\begin{itemize}
\item Use the definition: for every $\varepsilon > 0$, there exists $N$ such that $|f_n(x) - f(x)| < \varepsilon$ for all $n \geq N$ and all $x \in S$
\item Show that the maximum difference between $f_n$ and $f$ approaches zero
\item Use the triangle inequality: $|(f_n + g_n) - (f + g)| \leq |f_n - f| + |g_n - g|$
\item Apply the fact that uniform limits of continuous functions are continuous
\item Use the fact that uniform limits of bounded functions are bounded
\end{itemize}

\subsection*{Working with Bounded Functions}
\begin{itemize}
\item Use the fact that if $f_n \to f$ uniformly and each $f_n$ is bounded, then $\{f_n\}$ is uniformly bounded
\item Apply the triangle inequality to control products: $|f_n g_n - fg| \leq |f_n| |g_n - g| + |g| |f_n - f|$
\item Use boundedness to control the size of error terms in convergence proofs
\item Apply the fact that continuous functions on compact sets are uniformly continuous
\end{itemize}

\subsection*{Analyzing Pointwise vs Uniform Convergence}
\begin{itemize}
\item Show that pointwise convergence does not imply uniform convergence by finding points where the convergence is slow
\item Use the fact that uniform convergence preserves continuity, boundedness, and integrability
\item Apply the Weierstrass M-test for series: if $|f_n(x)| \leq M_n$ and $\sum M_n$ converges, then $\sum f_n$ converges uniformly
\item Use the fact that uniform convergence allows interchange of limits and integrals
\end{itemize}

\subsection*{Working with Power Series}
\begin{itemize}
\item Use the radius of convergence: $R = 1/\limsup_{n \to \infty} \sqrt[n]{|a_n|}$
\item Apply Abel's limit theorem: if $\sum a_n$ converges, then $\lim_{x \to 1^-} \sum a_n x^n = \sum a_n$
\item Use the fact that power series converge uniformly on compact subsets of their interval of convergence
\item Apply the Cauchy product formula for multiplying power series
\item Use the fact that power series can be differentiated and integrated term by term
\end{itemize}

\subsection*{Proving Tauberian Theorems}
\begin{itemize}
\item Use proof by contradiction: assume the series diverges and show this leads to a contradiction
\item Apply the fact that if $a_n \geq 0$ and $\sum a_n$ diverges, then $\sum a_n x^n \to +\infty$ as $x \to 1^-$
\item Use Abel's limit theorem to connect the limit of the power series to the sum of the series
\item Apply the fact that positive series either converge or diverge to $+\infty$
\end{itemize}

\subsection*{Working with Generating Functions}
\begin{itemize}
\item Use the fact that generating functions can be manipulated algebraically
\item Apply functional equations to derive properties of the coefficients
\item Use the Cauchy product formula to multiply generating functions
\item Apply differentiation and integration to derive recurrence relations
\item Use the fact that generating functions can be used to solve combinatorial problems
\end{itemize}